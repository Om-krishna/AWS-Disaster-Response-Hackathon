{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>RAINFALL(mm)</th>\n",
       "      <th>MIN-TEMP</th>\n",
       "      <th>MAX-TEMP</th>\n",
       "      <th>RELATIVE-HUMIDITY(%)</th>\n",
       "      <th>WATER-LEVEL(m)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>71.966667</td>\n",
       "      <td>14.735714</td>\n",
       "      <td>39.336</td>\n",
       "      <td>65.0</td>\n",
       "      <td>334.133462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>112.875000</td>\n",
       "      <td>14.735714</td>\n",
       "      <td>39.336</td>\n",
       "      <td>71.5</td>\n",
       "      <td>334.133462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>77.225000</td>\n",
       "      <td>14.735714</td>\n",
       "      <td>39.336</td>\n",
       "      <td>71.5</td>\n",
       "      <td>334.133462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>123.466667</td>\n",
       "      <td>14.735714</td>\n",
       "      <td>39.336</td>\n",
       "      <td>71.5</td>\n",
       "      <td>282.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>58.433333</td>\n",
       "      <td>14.735714</td>\n",
       "      <td>39.336</td>\n",
       "      <td>71.5</td>\n",
       "      <td>189.293000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  RAINFALL(mm)   MIN-TEMP  MAX-TEMP  RELATIVE-HUMIDITY(%)  \\\n",
       "0      0     71.966667  14.735714    39.336                  65.0   \n",
       "1      1    112.875000  14.735714    39.336                  71.5   \n",
       "2      0     77.225000  14.735714    39.336                  71.5   \n",
       "3      1    123.466667  14.735714    39.336                  71.5   \n",
       "4      0     58.433333  14.735714    39.336                  71.5   \n",
       "\n",
       "   WATER-LEVEL(m)  \n",
       "0      334.133462  \n",
       "1      334.133462  \n",
       "2      334.133462  \n",
       "3      282.060000  \n",
       "4      189.293000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('rawdata.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>RAINFALL(mm)</th>\n",
       "      <th>MIN-TEMP</th>\n",
       "      <th>MAX-TEMP</th>\n",
       "      <th>RELATIVE-HUMIDITY(%)</th>\n",
       "      <th>WATER-LEVEL(m)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>71.966667</td>\n",
       "      <td>14.735714</td>\n",
       "      <td>39.336</td>\n",
       "      <td>65.0</td>\n",
       "      <td>334.133462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>112.875000</td>\n",
       "      <td>14.735714</td>\n",
       "      <td>39.336</td>\n",
       "      <td>71.5</td>\n",
       "      <td>334.133462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>77.225000</td>\n",
       "      <td>14.735714</td>\n",
       "      <td>39.336</td>\n",
       "      <td>71.5</td>\n",
       "      <td>334.133462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>123.466667</td>\n",
       "      <td>14.735714</td>\n",
       "      <td>39.336</td>\n",
       "      <td>71.5</td>\n",
       "      <td>282.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>58.433333</td>\n",
       "      <td>14.735714</td>\n",
       "      <td>39.336</td>\n",
       "      <td>71.5</td>\n",
       "      <td>189.293000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  RAINFALL(mm)   MIN-TEMP  MAX-TEMP  RELATIVE-HUMIDITY(%)  \\\n",
       "0      0     71.966667  14.735714    39.336                  65.0   \n",
       "1      1    112.875000  14.735714    39.336                  71.5   \n",
       "2      0     77.225000  14.735714    39.336                  71.5   \n",
       "3      1    123.466667  14.735714    39.336                  71.5   \n",
       "4      0     58.433333  14.735714    39.336                  71.5   \n",
       "\n",
       "   WATER-LEVEL(m)  \n",
       "0      334.133462  \n",
       "1      334.133462  \n",
       "2      334.133462  \n",
       "3      282.060000  \n",
       "4      189.293000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.rename(columns={\"FLOOD\": \"Label\"}, inplace=True)\n",
    "lbl = data.Label\n",
    "data = pd.concat([lbl, data.drop(columns=['Label'])], axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version is good\n",
      "Region = ap-south-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import sys\n",
    "import IPython\n",
    "import os\n",
    "\n",
    "if int(sagemaker.__version__.split('.')[0]) == 2:\n",
    "    print(\"Installing previous SageMaker Version and restarting the kernel\")\n",
    "    !{sys.executable} -m pip install sagemaker==1.72.0\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)\n",
    "\n",
    "else:\n",
    "    print(\"Version is good\")\n",
    "\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = boto3.session.Session().region_name\n",
    "print(\"Region = {}\".format(region))\n",
    "sm = boto3.Session().client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: sagemaker-experiments in /opt/conda/lib/python3.7/site-packages (0.1.35)\n",
      "Requirement already satisfied: boto3>=1.16.27 in /opt/conda/lib/python3.7/site-packages (from sagemaker-experiments) (1.20.23)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.23 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (1.23.23)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.23->boto3>=1.16.27->sagemaker-experiments) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.23->boto3>=1.16.27->sagemaker-experiments) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.23->boto3>=1.16.27->sagemaker-experiments) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker-experiments \n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawbucket= sess.default_bucket() # Alternatively you can use our custom bucket here. \n",
    "\n",
    "prefix = 'sagemaker-modelmonitor' # use this prefix to store all files pertaining to this workshop.\n",
    "\n",
    "dataprefix = prefix + '/data'\n",
    "traindataprefix = prefix + '/train_data'\n",
    "testdataprefix = prefix + '/test_data'\n",
    "testdatanolabelprefix = prefix + '/test_data_no_label'\n",
    "trainheaderprefix = prefix + '/train_headers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-south-1-030462292417/sagemaker-modelmonitor/data\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('rawdata/rawdata.csv'):\n",
    "    !mkdir rawdata\n",
    "    data.to_csv('rawdata/rawdata.csv', index=None)\n",
    "else:\n",
    "    pass\n",
    "# Upload the raw dataset\n",
    "raw_data_location = sess.upload_data('rawdata', bucket=rawbucket, key_prefix=dataprefix)\n",
    "print(raw_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=role,\n",
    "                                     instance_type='ml.c4.xlarge',\n",
    "                                     instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train-test-split-ratio', type=float, default=0.3)\n",
    "    parser.add_argument('--random-split', type=int, default=0)\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    print('Received arguments {}'.format(args))\n",
    "\n",
    "    input_data_path = os.path.join('/opt/ml/processing/input', 'rawdata.csv')\n",
    "    \n",
    "    print('Reading input data from {}'.format(input_data_path))\n",
    "    df = pd.read_csv(input_data_path)\n",
    "    df.sample(frac=1)\n",
    "    \n",
    "    split_ratio = args.train_test_split_ratio\n",
    "    random_state=args.random_split\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.drop(columns = ['Label']), df['Label'], \n",
    "                                                        test_size=split_ratio, random_state=random_state)\n",
    "    \n",
    "    print('Running preprocessing and feature engineering transformations')\n",
    "    train_features = X_train\n",
    "    test_features = X_test\n",
    "    \n",
    "    # concat to ensure Label column is the first column in dataframe\n",
    "    train_full = pd.concat([pd.DataFrame(y_train.values, columns=['Label']), train_features], axis=1)\n",
    "    test_full = pd.concat([pd.DataFrame(y_test.values, columns=['Label']), test_features], axis=1)\n",
    "    \n",
    "    print('Train data shape after preprocessing: {}'.format(train_features.shape))\n",
    "    print('Test data shape after preprocessing: {}'.format(test_features.shape))\n",
    "    \n",
    "    train_features_headers_output_path = os.path.join('/opt/ml/processing/train_headers', 'train_data_with_headers.csv')\n",
    "    \n",
    "    train_features_output_path = os.path.join('/opt/ml/processing/train', 'train_data.csv')\n",
    "    \n",
    "    test_features_output_path = os.path.join('/opt/ml/processing/test', 'test_data.csv')\n",
    "    \n",
    "    print('Saving training features to {}'.format(train_features_output_path))\n",
    "    train_full.to_csv(train_features_output_path, header=False, index=False)\n",
    "    print(\"Complete\")\n",
    "    \n",
    "    print(\"Save training data with headers to {}\".format(train_features_headers_output_path))\n",
    "    train_full.to_csv(train_features_headers_output_path, index=False)\n",
    "                 \n",
    "    print('Saving test features to {}'.format(test_features_output_path))\n",
    "    test_full.to_csv(test_features_output_path, header=False, index=False)\n",
    "    print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-south-1-030462292417/sagemaker-modelmonitor/code/preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "# Copy the preprocessing code over to the s3 bucket\n",
    "codeprefix = prefix + '/code'\n",
    "codeupload = sess.upload_data('preprocessing.py', bucket=rawbucket, key_prefix=codeprefix)\n",
    "print(codeupload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data location = sagemaker-ap-south-1-030462292417/sagemaker-modelmonitor/train_data\n",
      "Test data location = sagemaker-ap-south-1-030462292417/sagemaker-modelmonitor/test_data\n"
     ]
    }
   ],
   "source": [
    "train_data_location = rawbucket + '/' + traindataprefix\n",
    "test_data_location = rawbucket+'/'+testdataprefix\n",
    "print(\"Training data location = {}\".format(train_data_location))\n",
    "print(\"Test data location = {}\".format(test_data_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name sagemaker-scikit-learn-2022-02-07-15-59-27-365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-scikit-learn-2022-02-07-15-59-27-365\n",
      "Inputs:  [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://sagemaker-ap-south-1-030462292417/sagemaker-modelmonitor/data', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-ap-south-1-030462292417/sagemaker-modelmonitor/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train_data', 'S3Output': {'S3Uri': 's3://sagemaker-ap-south-1-030462292417/sagemaker-modelmonitor/train_data', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test_data', 'S3Output': {'S3Uri': 's3://sagemaker-ap-south-1-030462292417/sagemaker-modelmonitor/test_data', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'train_data_headers', 'S3Output': {'S3Uri': 's3://sagemaker-ap-south-1-030462292417/sagemaker-modelmonitor/train_headers', 'LocalPath': '/opt/ml/processing/train_headers', 'S3UploadMode': 'EndOfJob'}}]\n",
      "..............................\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[34mReceived arguments Namespace(random_split=0, train_test_split_ratio=0.2)\u001b[0m\n",
      "\u001b[34mReading input data from /opt/ml/processing/input/rawdata.csv\u001b[0m\n",
      "\u001b[34mRunning preprocessing and feature engineering transformations\u001b[0m\n",
      "\u001b[34mTrain data shape after preprocessing: (40, 5)\u001b[0m\n",
      "\u001b[34mTest data shape after preprocessing: (10, 5)\u001b[0m\n",
      "\u001b[34mSaving training features to /opt/ml/processing/train/train_data.csv\u001b[0m\n",
      "\u001b[34mComplete\u001b[0m\n",
      "\u001b[34mSave training data with headers to /opt/ml/processing/train_headers/train_data_with_headers.csv\u001b[0m\n",
      "\u001b[34mSaving test features to /opt/ml/processing/test/test_data.csv\u001b[0m\n",
      "\u001b[34mComplete\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "sklearn_processor.run(code=codeupload,\n",
    "                      inputs=[ProcessingInput(\n",
    "                        source=raw_data_location,\n",
    "                        destination='/opt/ml/processing/input')],\n",
    "                      outputs=[ProcessingOutput(output_name='train_data',\n",
    "                                                source='/opt/ml/processing/train',\n",
    "                               destination='s3://' + train_data_location),\n",
    "                               ProcessingOutput(output_name='test_data',\n",
    "                                                source='/opt/ml/processing/test',\n",
    "                                               destination=\"s3://\"+test_data_location),\n",
    "                               ProcessingOutput(output_name='train_data_headers',\n",
    "                                                source='/opt/ml/processing/train_headers',\n",
    "                                               destination=\"s3://\" + rawbucket + '/' + prefix + '/train_headers')],\n",
    "                      arguments=['--train-test-split-ratio', '0.2']\n",
    "                     )\n",
    "\n",
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()\n",
    "\n",
    "output_config = preprocessing_job_description['ProcessingOutputConfig']\n",
    "for output in output_config['Outputs']:\n",
    "    if output['OutputName'] == 'train_data':\n",
    "        preprocessed_training_data = output['S3Output']['S3Uri']\n",
    "    if output['OutputName'] == 'test_data':\n",
    "        preprocessed_test_data = output['S3Output']['S3Uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment(sagemaker_boto_client=<botocore.client.SageMaker object at 0x7f4dab8a1cd0>,experiment_name='Build-train-deploy-1644249910',description='Predict FLOOD',tags=None,experiment_arn='arn:aws:sagemaker:ap-south-1:030462292417:experiment/build-train-deploy-1644249910',response_metadata={'RequestId': '13e7854c-e337-47e7-ac33-0a8c2b4016be', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '13e7854c-e337-47e7-ac33-0a8c2b4016be', 'content-type': 'application/x-amz-json-1.1', 'content-length': '102', 'date': 'Mon, 07 Feb 2022 16:05:10 GMT'}, 'RetryAttempts': 0})\n"
     ]
    }
   ],
   "source": [
    "# Create a SageMaker Experiment\n",
    "cc_experiment = Experiment.create(\n",
    "    experiment_name=f\"Build-train-deploy-{int(time.time())}\", \n",
    "    description=\"Predict FLOOD\", \n",
    "    sagemaker_boto_client=sm)\n",
    "print(cc_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Tracking parameters used in the Pre-processing pipeline.\n",
    "with Tracker.create(display_name=\"Preprocessing\", sagemaker_boto_client=sm) as tracker:\n",
    "    tracker.log_parameters({\n",
    "        \"train_test_split_ratio\": 0.2,\n",
    "        \"random_state\":0\n",
    "    })\n",
    "    # we can log the s3 uri to the dataset we just uploaded\n",
    "    tracker.log_input(name=\"ccdefault-raw-dataset\", media_type=\"s3/uri\", value=raw_data_location)\n",
    "    tracker.log_input(name=\"ccdefault-train-dataset\", media_type=\"s3/uri\", value=train_data_location)\n",
    "    tracker.log_input(name=\"ccdefault-test-dataset\", media_type=\"s3/uri\", value=test_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.amazon.amazon_estimator:'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker.estimator:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "INFO:sagemaker:Creating training-job with name: cc-training-job-1644250050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-07 16:07:30 Starting - Starting the training job...\n",
      "2022-02-07 16:07:56 Starting - Preparing the instances for training......\n",
      "2022-02-07 16:08:59 Downloading - Downloading input data...\n",
      "2022-02-07 16:09:30 Training - Downloading the training image........\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value multi:softmax to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[16:10:40] 49x5 matrix with 236 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 49 rows\u001b[0m\n",
      "\u001b[34m[16:10:40] WARNING: /workspace/src/learner.cc:328: \u001b[0m\n",
      "\u001b[34mParameters: { num_round } might not be used.\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\u001b[0m\n",
      "\u001b[34m[0]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[1]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[2]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[3]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[4]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[5]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[6]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[7]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[8]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[9]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[10]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[11]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[12]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[13]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[14]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[15]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[16]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[17]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[18]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[19]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[20]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[21]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[22]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[23]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[24]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[25]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[26]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[27]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[28]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[29]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[30]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[31]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[32]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[33]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[34]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[35]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[36]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[37]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[38]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[39]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[40]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[41]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[42]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[43]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[44]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[45]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[46]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[47]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[48]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[49]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[50]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[51]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[52]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[53]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[54]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[55]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[56]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[57]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[58]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[59]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[60]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[61]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[62]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[63]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[64]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[65]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[66]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[67]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[68]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[69]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[70]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[71]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[72]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[73]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[74]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[75]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[76]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[77]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[78]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[79]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[80]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[81]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[82]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[83]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[84]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[85]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[86]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[87]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[88]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[89]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[90]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[91]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[92]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[93]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[94]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[95]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[96]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[97]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[98]#011train-merror:0.34694\u001b[0m\n",
      "\u001b[34m[99]#011train-merror:0.34694\u001b[0m\n",
      "\n",
      "2022-02-07 16:10:52 Uploading - Uploading generated training model\n",
      "2022-02-07 16:10:52 Completed - Training job completed\n",
      "Training seconds: 113\n",
      "Billable seconds: 113\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost', '1.0-1')\n",
    "s3_input_train = sagemaker.s3_input(s3_data='s3://' + train_data_location, content_type='csv')\n",
    "preprocessing_trial_component = tracker.trial_component\n",
    "\n",
    "trial_name = f\"cc-default-training-job-{int(time.time())}\"\n",
    "cc_trial = Trial.create(\n",
    "        trial_name=trial_name, \n",
    "            experiment_name=cc_experiment.experiment_name,\n",
    "        sagemaker_boto_client=sm\n",
    "    )\n",
    "\n",
    "cc_trial.add_trial_component(preprocessing_trial_component)\n",
    "cc_training_job_name = \"cc-training-job-{}\".format(int(time.time()))\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    train_max_run=86400,\n",
    "                                    output_path='s3://{}/{}/models'.format(rawbucket, prefix),\n",
    "                                    sagemaker_session=sess) # set to true for distributed training\n",
    "\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='multi:softmax',\n",
    "                        num_round=100,\n",
    "                        num_class=3)\n",
    "\n",
    "xgb.fit(inputs = {'train':s3_input_train},\n",
    "       job_name=cc_training_job_name,\n",
    "        experiment_config={\n",
    "            \"TrialName\": cc_trial.trial_name, #log training job in Trials for lineage\n",
    "            \"TrialComponentDisplayName\": \"Training\",\n",
    "        },\n",
    "        wait=True\n",
    "    )\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-ap-south-1-030462292417/sagemaker-modelmonitor/test_data/test_data.csv to ./test_data.csv\n"
     ]
    }
   ],
   "source": [
    "test_data_path = 's3://' + test_data_location + '/test_data.csv'\n",
    "! aws s3 cp $test_data_path ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>77.225000</td>\n",
       "      <td>14.735714</td>\n",
       "      <td>39.336</td>\n",
       "      <td>71.5</td>\n",
       "      <td>334.133462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>58.433333</td>\n",
       "      <td>14.735714</td>\n",
       "      <td>39.336</td>\n",
       "      <td>71.5</td>\n",
       "      <td>189.293000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0          1          2       3     4           5\n",
       "0  0.0        NaN        NaN     NaN   NaN         NaN\n",
       "1  2.0        NaN        NaN     NaN   NaN         NaN\n",
       "2  1.0  77.225000  14.735714  39.336  71.5  334.133462\n",
       "3  0.0        NaN        NaN     NaN   NaN         NaN\n",
       "4  0.0  58.433333  14.735714  39.336  71.5  189.293000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_full = pd.read_csv('test_data.csv', names = [str(x) for x in range(len(data.columns))])\n",
    "test_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = test_full['0'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "INFO:sagemaker:Creating model with name: cc-training-job-1644250050\n",
      "INFO:sagemaker:Creating transform job with name: sagemaker-xgboost-2022-02-07-16-11-54-091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\u001b[34m[2022-02-07:16:15:55:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-02-07:16:15:55:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-02-07:16:15:55:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2022-02-07 16:15:55 +0000] [19] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2022-02-07 16:15:55 +0000] [19] [INFO] Listening at: unix:/tmp/gunicorn.sock (19)\u001b[0m\n",
      "\u001b[34m[2022-02-07 16:15:55 +0000] [19] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2022-02-07 16:15:55 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2022-02-07 16:15:55 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[34m[2022-02-07 16:15:55 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[34m[2022-02-07 16:15:55 +0000] [29] [INFO] Booting worker with pid: 29\u001b[0m\n",
      "\u001b[34m[2022-02-07:16:16:00:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [07/Feb/2022:16:16:00 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2022-02-07:16:16:00:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [07/Feb/2022:16:16:00 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2022-02-07:16:16:00:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [07/Feb/2022:16:16:00 +0000] \"POST /invocations HTTP/1.1\" 200 72 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2022-02-07T16:16:00.142:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "CPU times: user 536 ms, sys: 42.8 ms, total: 579 ms\n",
      "Wall time: 4min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sm_transformer = xgb.transformer(1, 'ml.m5.xlarge', accept = 'text/csv')\n",
    "\n",
    "# start a transform job\n",
    "sm_transformer.transform(test_data_path, split_type='Line', input_filter='$[1:]', content_type='text/csv')\n",
    "sm_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0.0  1.0  2.0  All\n",
       "Actual                       \n",
       "0.0          1    1    0    2\n",
       "1.0          4    2    2    8\n",
       "All          5    3    2   10"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import io\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def get_csv_output_from_s3(s3uri, file_name):\n",
    "    parsed_url = urlparse(s3uri)\n",
    "    bucket_name = parsed_url.netloc\n",
    "    prefix = parsed_url.path[1:]\n",
    "    s3 = boto3.resource('s3')\n",
    "    obj = s3.Object(bucket_name, '{}/{}'.format(prefix, file_name))\n",
    "    return obj.get()[\"Body\"].read().decode('utf-8')\n",
    "output = get_csv_output_from_s3(sm_transformer.output_path, 'test_data.csv.out')\n",
    "output_df = pd.read_csv(io.StringIO(output), sep=\",\", header=None)\n",
    "output_df.head(8)\n",
    "output_df['Predicted']=np.round(output_df.values)\n",
    "output_df['Label'] = label\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "confusion_matrix = pd.crosstab(output_df['Predicted'], output_df['Label'], rownames=['Actual'], colnames=['Predicted'], margins = True)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created: arn:aws:sagemaker:ap-south-1:030462292417:model/cc-training-job-1644250050\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "from sagemaker import RealTimePredictor\n",
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "latest_training_job = sm_client.list_training_jobs(MaxResults=1,\n",
    "                                                SortBy='CreationTime',\n",
    "                                                SortOrder='Descending')\n",
    "\n",
    "training_job_name=TrainingJobName=latest_training_job['TrainingJobSummaries'][0]['TrainingJobName']\n",
    "\n",
    "training_job_description = sm_client.describe_training_job(TrainingJobName=training_job_name)\n",
    "\n",
    "model_data = training_job_description['ModelArtifacts']['S3ModelArtifacts']\n",
    "container_uri = training_job_description['AlgorithmSpecification']['TrainingImage']\n",
    "\n",
    "# create a model.\n",
    "def create_model(role, model_name, container_uri, model_data):\n",
    "    return sm_client.create_model(\n",
    "        ModelName=model_name,\n",
    "        PrimaryContainer={\n",
    "        'Image': container_uri,\n",
    "        'ModelDataUrl': model_data,\n",
    "        },\n",
    "        ExecutionRoleArn=role)\n",
    "    \n",
    "\n",
    "try:\n",
    "    model = create_model(role, training_job_name, container_uri, model_data)\n",
    "except Exception as e:\n",
    "        sm_client.delete_model(ModelName=training_job_name)\n",
    "        model = create_model(role, training_job_name, container_uri, model_data)\n",
    "        \n",
    "\n",
    "print('Model created: '+model['ModelArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_capture_upload_path = 's3://{}/{}/monitoring/datacapture'.format(rawbucket, prefix)\n",
    "data_capture_configuration = {\n",
    "    \"EnableCapture\": True,\n",
    "    \"InitialSamplingPercentage\": 100,\n",
    "    \"DestinationS3Uri\": s3_capture_upload_path,\n",
    "    \"CaptureOptions\": [\n",
    "        { \"CaptureMode\": \"Output\" },\n",
    "        { \"CaptureMode\": \"Input\" }\n",
    "    ],\n",
    "    \"CaptureContentTypeHeader\": {\n",
    "       \"CsvContentTypes\": [\"text/csv\"],\n",
    "       \"JsonContentTypes\": [\"application/json\"]}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint configuration created: arn:aws:sagemaker:ap-south-1:030462292417:endpoint-config/cc-training-job-1644250050\n"
     ]
    }
   ],
   "source": [
    "def create_endpoint_config(model_config, data_capture_config): \n",
    "    return sm_client.create_endpoint_config(\n",
    "                                                EndpointConfigName=model_config,\n",
    "                                                ProductionVariants=[\n",
    "                                                        {\n",
    "                                                            'VariantName': 'AllTraffic',\n",
    "                                                            'ModelName': model_config,\n",
    "                                                            'InitialInstanceCount': 1,\n",
    "                                                            'InstanceType': 'ml.m4.xlarge',\n",
    "                                                            'InitialVariantWeight': 1.0,\n",
    "                                                },\n",
    "                                                    \n",
    "                                                    ],\n",
    "                                                DataCaptureConfig=data_capture_config\n",
    "                                                )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    endpoint_config = create_endpoint_config(training_job_name, data_capture_configuration)\n",
    "except Exception as e:\n",
    "    sm_client.delete_endpoint_config(EndpointConfigName=endpoint)\n",
    "    endpoint_config = create_endpoint_config(training_job_name, data_capture_configuration)\n",
    "\n",
    "print('Endpoint configuration created: '+ endpoint_config['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint created: arn:aws:sagemaker:ap-south-1:030462292417:endpoint/cc-training-job-1644250050\n"
     ]
    }
   ],
   "source": [
    "# Enable data capture, sampling 100% of the data for now. Next we deploy the endpoint in the correct VPC.\n",
    "\n",
    "endpoint_name = training_job_name\n",
    "def create_endpoint(endpoint_name, config_name):\n",
    "    return sm_client.create_endpoint(\n",
    "                                    EndpointName=endpoint_name,\n",
    "                                    EndpointConfigName=training_job_name\n",
    "                                )\n",
    "\n",
    "\n",
    "try:\n",
    "    endpoint = create_endpoint(endpoint_name, endpoint_config)\n",
    "except Exception as e:\n",
    "    sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "    endpoint = create_endpoint(endpoint_name, endpoint_config)\n",
    "\n",
    "print('Endpoint created: '+ endpoint['EndpointArn'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-south-1:394103062818:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
